openapi: 3.0.0
info:
  title: Anthropic Text Completion API
  version: 1.0.0
  description: API for text completion using Anthropic's language models. This specification is based on the documentation at https://docs.anthropic.com/en/api/complete.

servers:
  - url: https://api.anthropic.com/v1

paths:
  /complete:
    post:
      summary: Create a text completion
      operationId: createCompletion
      tags:
        - TextCompletion
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CompletionRequest"
      responses:
        "200":
          description: Successful response
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CompletionResponse"

components:
  securitySchemes:
    ApiKeyAuth:
      type: apiKey
      in: header
      name: x-api-key
      description: Your unique API key for authentication. This key is required in the header of all API requests, to authenticate your account and access Anthropic's services. Get your API key through the Console. Each key is scoped to a Workspace.
    AnthropicVersionHeader:
      type: apiKey
      in: header
      name: anthropic-version
      description: The version of the Anthropic API you want to use. Read more about versioning and our version history here.

  schemas:
    CompletionRequest:
      type: object
      required:
        - model
        - prompt
      properties:
        model:
          type: string
          description: The model that will complete your prompt. See models for additional details and options.
        prompt:
          type: string
          description: The prompt that you want Claude to complete. For proper response generation, format your prompt using alternating "\n\nHuman:" and "\n\nAssistant:" conversational turns.
        max_tokens_to_sample:
          type: integer
          description: The maximum number of tokens to generate before stopping. Note that our models may stop before reaching this maximum.
        stop_sequences:
          type: array
          items:
            type: string
          description: Sequences that will cause the model to stop generating. Our models stop on "\n\nHuman:", and may include additional built-in stop sequences in the future.
        temperature:
          type: number
          default: 1.0
          minimum: 0.0
          maximum: 1.0
          description: Amount of randomness injected into the response. Defaults to 1.0. Ranges from 0.0 to 1.0.
        top_p:
          type: number
          description: Use nucleus sampling. You should either alter temperature or top_p, but not both.
        top_k:
          type: integer
          description: Only sample from the top K options for each subsequent token. Used to remove "long tail" low probability responses.
        metadata:
          type: object
          description: An object describing metadata about the request.
        stream:
          type: boolean
          description: Whether to incrementally stream the response using server-sent events.

    CompletionResponse:
      type: object
      required:
        - completion
        - stop_reason
        - model
      properties:
        completion:
          type: string
          description: The resulting completion up to and excluding the stop sequences.
        stop_reason:
          type: string
          enum: [stop_sequence, max_tokens]
          description: The reason that we stopped generating tokens.
        model:
          type: string
          description: The model that handled the request.
        type:
          type: string
          enum: [completion]
          description: Object type. For Text Completions, this is always "completion".
        id:
          type: string
          description: Unique object identifier. The format and length of IDs may change over time.

security:
  - ApiKeyAuth: []
    AnthropicVersionHeader: []
